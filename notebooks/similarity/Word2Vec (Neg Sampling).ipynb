{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "from app.classes.skipgram_neg_model import SkipgramNeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../app/models/skipgram_neg/skipgram_neg.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "with open('../../app/models/skipgram_neg/skipgram_neg_word2index.pkl', 'rb') as f:\n",
    "    word2index = pickle.load(f)\n",
    "\n",
    "with open('../../app/models/skipgram_neg/skipgram_neg_index2word.pkl', 'rb') as f:\n",
    "    index2word = pickle.load(f)\n",
    "\n",
    "center_embeddings = model.embedding_center.weight.data\n",
    "outside_embeddings = model.embedding_outside.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(word):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except:\n",
    "        index = word2index['<UNK>']\n",
    "        \n",
    "    word = torch.LongTensor([word2index[word]])\n",
    "    \n",
    "    embed_c = model.embedding_center(word)\n",
    "    embed_o = model.embedding_outside(word)\n",
    "    embed   = (embed_c + embed_o) / 2\n",
    "    \n",
    "    return embed[0][0].item(), embed[0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more formally is to divide by its norm\n",
    "def get_dot_product(A, B):\n",
    "    dot_product = np.dot(A, B)\n",
    "    return dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../helper/wordsim_similarity_goldstandard.txt', 'r') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "lines = [line.strip().replace('\\t', ' ').split() for line in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignificanceResult(statistic=-0.05912540751272472, pvalue=0.4020651027047055)\n",
      "33.39268596678153\n"
     ]
    }
   ],
   "source": [
    "similarity = []\n",
    "\n",
    "for line in lines:\n",
    "    word1 = line[0]\n",
    "    word2 = line[1]\n",
    "    score = float(line[2])\n",
    "\n",
    "    try:\n",
    "        similarity.append(get_dot_product(get_embed(word1), get_embed(word2)))\n",
    "    except:\n",
    "        similarity.append(0.0)\n",
    "\n",
    "# find the Spearman Correlation\n",
    "spearman_correlation = spearmanr(similarity, [line[2] for line in lines])\n",
    "print(spearman_correlation)\n",
    "\n",
    "# find the MSE\n",
    "squared_error = [(similarity[i] - float(lines[i][2]))**2 for i in range(len(similarity))]\n",
    "mse = sum(squared_error) / len(similarity)\n",
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
