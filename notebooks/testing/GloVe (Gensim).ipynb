{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import requests\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "from app.classes.glove_model import Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../app/models/glove_gensim/glove_gensim.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy_url = \"https://www.fit.vutbr.cz/~imikolov/rnnlm/word-test.v1.txt\"\n",
    "\n",
    "def load_word_analogy_data_for_syntactic_accuracy(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    lines = response.text.strip().split('\\n')\n",
    "    \n",
    "    # Extract specific section\n",
    "    section_start = ': gram7-past-tense'\n",
    "    section_end = ': gram8-plural'\n",
    "    extract_lines = []\n",
    "    in_section = False\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(section_start):\n",
    "            in_section = True\n",
    "            continue\n",
    "        elif line.startswith(section_end):\n",
    "            break\n",
    "\n",
    "        if in_section:\n",
    "            extract_lines.append(line)\n",
    "\n",
    "    return [line.split() for line in extract_lines if line]\n",
    "\n",
    "def load_word_analogy_data_for_semantic_accuracy(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    lines = response.text.strip().split('\\n')\n",
    "    \n",
    "    # Extract specific section\n",
    "    section_start = ': capital-common-countries'\n",
    "    section_end = ': currency'\n",
    "    extract_lines = []\n",
    "    in_section = False\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(section_start):\n",
    "            in_section = True\n",
    "            continue\n",
    "        elif line.startswith(section_end):\n",
    "            break\n",
    "\n",
    "        if in_section:\n",
    "            extract_lines.append(line)\n",
    "\n",
    "    return [line.split() for line in extract_lines if line]\n",
    "\n",
    "syntactic_analogy_data = load_word_analogy_data_for_syntactic_accuracy(analogy_url)\n",
    "semantic_analogy_data = load_word_analogy_data_for_semantic_accuracy(analogy_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_analogy(word_a, word_b, word_c):\n",
    "    result = model.most_similar(positive=[word_c, word_b], negative=[word_a])\n",
    "    return result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_semantic_accuracy(analogy_data):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for question in analogy_data:\n",
    "        if len(question) != 4:\n",
    "            continue\n",
    "        word_a, word_b, word_c, word_d = question\n",
    "        try:\n",
    "            predicted_word = predict_analogy(word_a, word_b, word_c)\n",
    "        except:\n",
    "            predicted_word = None\n",
    "\n",
    "        if predicted_word == word_d:\n",
    "            correct += 1\n",
    "\n",
    "        total += 1\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_syntactic_accuracy(analogy_data):\n",
    "    syntactic_correct = 0\n",
    "    syntactic_total = 0\n",
    "\n",
    "    for question in analogy_data:\n",
    "        if len(question) != 4:\n",
    "            continue\n",
    "        word_a, word_b, word_c, word_d = question\n",
    "        # Process syntactic relationships directly from the dataset\n",
    "        if word_a.endswith(\"ing\") and word_b.endswith(\"ed\") and word_c.endswith(\"ing\") and word_d.endswith(\"ed\"):\n",
    "            try:\n",
    "                predicted_word = predict_analogy(word_a, word_b, word_c)\n",
    "            except:\n",
    "                predicted_word = None\n",
    "\n",
    "            if predicted_word == word_d:\n",
    "                syntactic_correct += 1\n",
    "\n",
    "            syntactic_total += 1\n",
    "\n",
    "    syntactic_accuracy = syntactic_correct / syntactic_total if syntactic_total > 0 else 0\n",
    "    return syntactic_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syntactic Accuracy: 2.29%\n",
      "Semantic Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "syntactic_accuracy = evaluate_syntactic_accuracy(syntactic_analogy_data)\n",
    "semantic_accuracy = evaluate_semantic_accuracy(semantic_analogy_data)\n",
    "\n",
    "print(f\"Syntactic Accuracy: {syntactic_accuracy * 100:.2f}%\")\n",
    "print(f\"Semantic Accuracy: {semantic_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
