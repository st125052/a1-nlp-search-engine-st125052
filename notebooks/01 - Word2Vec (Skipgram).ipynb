{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec (Skipgram )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from string import punctuation\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\swara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\swara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import matplotlib\n",
    "nltk.download('stopwords')\n",
    "nltk.download('brown')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = brown.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "corpus = [[word for word in sent if word.lower() not in stop_words] for sent in corpus]\n",
    "\n",
    "# Remove punctuation from corpus\n",
    "corpus = [[word for word in sent if word not in punctuation] for sent in corpus]\n",
    "\n",
    "# Remove empty sentences\n",
    "corpus = [sent for sent in corpus if len(sent) > 0]\n",
    "\n",
    "# Remove sentences with less than 5 words\n",
    "corpus = [sent for sent in corpus if len(sent) >= 5]\n",
    "\n",
    "# Remove sentences with more than 20 words\n",
    "corpus = [sent for sent in corpus if len(sent) <= 20]\n",
    "\n",
    "# Remove rare words\n",
    "word_freq = Counter([word for sent in corpus for word in sent])\n",
    "corpus = [[word for word in sent if word_freq[word] > 5] for sent in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. numeralization\n",
    "#find unique words\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "#assign unique integer\n",
    "vocabs = list(set(flatten(corpus))) #all the words we have in the system - <UNK>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3158"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create handy mapping between integer and word\n",
    "word2index = {v:idx for idx, v in enumerate(vocabs)}\n",
    "word2index['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs.append('<UNK>')\n",
    "word2index['<UNK>'] = len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<UNK>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2word = {v:k for k, v in word2index.items()}\n",
    "index2word[len(index2word) - 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pairs of center word, and outside word\n",
    "\n",
    "def random_batch(batch_size, corpus, window_size=2):\n",
    "\n",
    "    skipgrams = []\n",
    "\n",
    "    #loop each corpus\n",
    "    for doc in corpus:\n",
    "        #look from the 2nd word until second last word\n",
    "        for i in range(window_size, len(doc) - window_size):\n",
    "            #center word\n",
    "            center = word2index[doc[i]]\n",
    "            #outside words = rest of the words\n",
    "            outside_start =  i - window_size\n",
    "            outside_end =  i + window_size + 1\n",
    "\n",
    "            for j in range(outside_start, outside_end):\n",
    "                if i != j:  # Skip the center word\n",
    "                    outside = word2index[doc[j]]\n",
    "                    skipgrams.append([center, outside])\n",
    "                \n",
    "    random_index = np.random.choice(range(len(skipgrams)), batch_size, replace=False)\n",
    "    \n",
    "    inputs, labels = [], []\n",
    "    for index in random_index:\n",
    "        inputs.append([skipgrams[index][0]])\n",
    "        labels.append([skipgrams[index][1]])\n",
    "        \n",
    "    return np.array(inputs), np.array(labels)\n",
    "            \n",
    "x, y = random_batch(2, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape  #batch_size, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2911],\n",
       "       [8851]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape  #batch_size 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model\n",
    "\n",
    "$$J(\\theta) = -\\frac{1}{T}\\sum_{t=1}^{T}\\sum_{\\substack{-m \\leq j \\leq m \\\\ j \\neq 0}}\\log P(w_{t+j} | w_t; \\theta)$$\n",
    "\n",
    "where $P(w_{t+j} | w_t; \\theta) = $\n",
    "\n",
    "$$P(o|c)=\\frac{\\exp(\\mathbf{u_o^{\\top}v_c})}{\\sum_{w=1}^V\\exp(\\mathbf{u_w^{\\top}v_c})}$$\n",
    "\n",
    "where $o$ is the outside words and $c$ is the center word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10583"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(len(vocabs), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor = torch.LongTensor(x)\n",
    "embedding(x_tensor).shape  #(batch_size, 1, emb_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(o|c)=\\frac{\\exp(\\mathbf{u_o^{\\top}v_c})}{\\sum_{w=1}^V\\exp(\\mathbf{u_w^{\\top}v_c})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(Skipgram, self).__init__()\n",
    "        self.embedding_center  = nn.Embedding(voc_size, emb_size)\n",
    "        self.embedding_outside = nn.Embedding(voc_size, emb_size)\n",
    "    \n",
    "    def forward(self, center, outside, all_vocabs):\n",
    "        center_embedding     = self.embedding_center(center)  #(batch_size, 1, emb_size)\n",
    "        outside_embedding    = self.embedding_center(outside) #(batch_size, 1, emb_size)\n",
    "        all_vocabs_embedding = self.embedding_center(all_vocabs) #(batch_size, voc_size, emb_size)\n",
    "        \n",
    "        top_term = torch.exp(outside_embedding.bmm(center_embedding.transpose(1, 2)).squeeze(2))\n",
    "        #batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) = (batch_size, 1) \n",
    "\n",
    "        lower_term = all_vocabs_embedding.bmm(center_embedding.transpose(1, 2)).squeeze(2)\n",
    "        #batch_size, voc_size, emb_size) @ (batch_size, emb_size, 1) = (batch_size, voc_size, 1) = (batch_size, voc_size) \n",
    "        \n",
    "        lower_term_sum = torch.sum(torch.exp(lower_term), 1)  #(batch_size, 1)\n",
    "        \n",
    "        loss = -torch.mean(torch.log(top_term / lower_term_sum))  #scalar\n",
    "        \n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     1,     2,  ..., 10580, 10581, 10582],\n",
       "        [    0,     1,     2,  ..., 10580, 10581, 10582]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare all vocabs\n",
    "\n",
    "batch_size = 2\n",
    "voc_size   = len(vocabs)\n",
    "\n",
    "def prepare_sequence(seq, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)\n",
    "\n",
    "all_vocabs = prepare_sequence(list(vocabs), word2index).expand(batch_size, voc_size)\n",
    "all_vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skipgram(\n",
       "  (embedding_center): Embedding(10583, 2)\n",
       "  (embedding_outside): Embedding(10583, 2)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Skipgram(voc_size, 2)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.LongTensor(x)\n",
    "label_tensor = torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(input_tensor, label_tensor, all_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.0398, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "emb_size   = 2\n",
    "model      = Skipgram(voc_size, emb_size)\n",
    "optimizer  = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 | Loss: 9.686029 | Time: 1m 23s\n",
      "Epoch: 200 | Loss: 9.613126 | Time: 2m 42s\n",
      "Epoch: 300 | Loss: 10.529035 | Time: 4m 1s\n",
      "Epoch: 400 | Loss: 9.488087 | Time: 5m 19s\n",
      "Epoch: 500 | Loss: 8.416470 | Time: 6m 40s\n",
      "Epoch: 600 | Loss: 9.561131 | Time: 8m 0s\n",
      "Epoch: 700 | Loss: 9.829943 | Time: 9m 20s\n",
      "Epoch: 800 | Loss: 10.165442 | Time: 10m 38s\n",
      "Epoch: 900 | Loss: 8.747721 | Time: 11m 54s\n",
      "Epoch: 1000 | Loss: 8.801099 | Time: 13m 11s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "num_epochs = 1000\n",
    "window_size = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #get batch\n",
    "    input_batch, label_batch = random_batch(batch_size, corpus, window_size)\n",
    "    input_tensor = torch.LongTensor(input_batch)\n",
    "    label_tensor = torch.LongTensor(label_batch)\n",
    "    \n",
    "    #predict\n",
    "    loss = model(input_tensor, label_tensor, all_vocabs)\n",
    "    \n",
    "    #backprogate\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    #update alpha\n",
    "    optimizer.step()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start, time.time())\n",
    "    \n",
    "    #print the loss\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch: {epoch + 1} | Loss: {loss:.6f} | Time: {epoch_mins}m {epoch_secs}s\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot the embeddings\n",
    "\n",
    "Is fruit really near to fish?\n",
    "Is fruit really far from cat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['evil',\n",
       " 'accelerometer',\n",
       " '200',\n",
       " 'fish',\n",
       " 'mimesis',\n",
       " 'detectives',\n",
       " 'paste',\n",
       " 'intend',\n",
       " 'odors',\n",
       " 'draw',\n",
       " 'Warsaw',\n",
       " 'bears',\n",
       " 'thief',\n",
       " 'develop',\n",
       " 'butter',\n",
       " 'swell',\n",
       " 'ads',\n",
       " 'differently',\n",
       " 'requests',\n",
       " 'H',\n",
       " 'Methodist',\n",
       " 'architectural',\n",
       " 'smell',\n",
       " 'Sponsor',\n",
       " 'Cologne',\n",
       " '2:37',\n",
       " 'chapter',\n",
       " 'utterly',\n",
       " 'break',\n",
       " 'i.e.',\n",
       " 'Riverside',\n",
       " 'towels',\n",
       " 'tires',\n",
       " 'Bright',\n",
       " 'conclusive',\n",
       " 'experts',\n",
       " 'blanket',\n",
       " 'Shelley',\n",
       " 'illustration',\n",
       " 'radio',\n",
       " 'waste',\n",
       " 'Sea',\n",
       " 'Civil',\n",
       " 'verse',\n",
       " 'boss',\n",
       " 'inspection',\n",
       " 'non-violent',\n",
       " 'addition',\n",
       " 'healthy',\n",
       " 'homely',\n",
       " 'proclaimed',\n",
       " 'unimportant',\n",
       " 'Homeric',\n",
       " 'candle',\n",
       " 'Blue',\n",
       " 'indebted',\n",
       " 'Usually',\n",
       " 'ashamed',\n",
       " 'decks',\n",
       " 'bought',\n",
       " 'committees',\n",
       " 'fresh',\n",
       " \"they've\",\n",
       " 'dust',\n",
       " 'tightly',\n",
       " 'anxious',\n",
       " 'troubled',\n",
       " 'battle',\n",
       " 'prone',\n",
       " 'availability',\n",
       " 'dedicated',\n",
       " 'Highlands',\n",
       " 'E.',\n",
       " 'friendship',\n",
       " 'grinning',\n",
       " 'Life',\n",
       " 'drops',\n",
       " 'appearances',\n",
       " 'happened',\n",
       " 'sensational',\n",
       " 'alliance',\n",
       " 'sample',\n",
       " 'commercials',\n",
       " 'erected',\n",
       " 'weakness',\n",
       " 'Anything',\n",
       " 'swayed',\n",
       " 'equal',\n",
       " 'Look',\n",
       " 'choked',\n",
       " 'Germans',\n",
       " 'corner',\n",
       " 'multiplied',\n",
       " 'Organization',\n",
       " 'Mary',\n",
       " 'net',\n",
       " 'select',\n",
       " 'theological',\n",
       " 'corps',\n",
       " 'edition',\n",
       " 'Lao',\n",
       " 'talking',\n",
       " 'stereotype',\n",
       " 'bullet',\n",
       " 'clarify',\n",
       " 'Katie',\n",
       " 'cream',\n",
       " 'account',\n",
       " 'Station',\n",
       " 'heavens',\n",
       " 'monument',\n",
       " 'smoothed',\n",
       " 'lengthy',\n",
       " 'Everything',\n",
       " 'perhaps',\n",
       " 'dark',\n",
       " 'quick',\n",
       " 'gang',\n",
       " 'wave',\n",
       " 'Johnnie',\n",
       " 'shed',\n",
       " 'Last',\n",
       " 'defending',\n",
       " 'notches',\n",
       " 'fails',\n",
       " 'employment',\n",
       " 'farther',\n",
       " 'hen',\n",
       " 'unnatural',\n",
       " 'receives',\n",
       " 'danced',\n",
       " 'necessitated',\n",
       " 'philosophers',\n",
       " 'guards',\n",
       " 'temper',\n",
       " 'climax',\n",
       " 'ten',\n",
       " 'trotted',\n",
       " 'pathological',\n",
       " 'exclusive',\n",
       " 'wire',\n",
       " 'obstacle',\n",
       " 'northeast',\n",
       " 'desert',\n",
       " 'almost',\n",
       " 'polls',\n",
       " 'guessing',\n",
       " 'poured',\n",
       " 'brings',\n",
       " 'expectation',\n",
       " 'Beethoven',\n",
       " 'Fig.',\n",
       " 'flour',\n",
       " 'spectacle',\n",
       " 'concerns',\n",
       " 'provide',\n",
       " 'conclude',\n",
       " 'vases',\n",
       " 'root',\n",
       " 'elicited',\n",
       " 'Senator',\n",
       " 'Baltimore',\n",
       " 'personally',\n",
       " 'graduates',\n",
       " 'stuff',\n",
       " 'applicable',\n",
       " 'Corporation',\n",
       " 'egg',\n",
       " 'lane',\n",
       " 'Carleton',\n",
       " 'creep',\n",
       " 'adopt',\n",
       " 'belonged',\n",
       " 'wishful',\n",
       " 'lessened',\n",
       " 'adding',\n",
       " 'directional',\n",
       " 'Fund',\n",
       " 'Peter',\n",
       " 'joints',\n",
       " 'bounce',\n",
       " 'grotesque',\n",
       " 'transfers',\n",
       " 'Laboratory',\n",
       " 'composite',\n",
       " 'Garibaldi',\n",
       " 'ministry',\n",
       " 'confusion',\n",
       " 'knows',\n",
       " 'Wisconsin',\n",
       " 'limiting',\n",
       " 'participating',\n",
       " 'labeled',\n",
       " 'corrected',\n",
       " 'birds',\n",
       " 'classics',\n",
       " 'purse',\n",
       " 'neither',\n",
       " 'printing',\n",
       " 'Wales',\n",
       " 'predicted',\n",
       " 'stretch',\n",
       " 'touch',\n",
       " 'Memphis',\n",
       " 'wildly',\n",
       " \"enemy's\",\n",
       " 'trains',\n",
       " 'effects',\n",
       " 'cook',\n",
       " 'turned',\n",
       " 'border',\n",
       " 'Esther',\n",
       " 'reference',\n",
       " 'exhausted',\n",
       " 'answers',\n",
       " 'submitted',\n",
       " 'Phil',\n",
       " 'mostly',\n",
       " 'checked',\n",
       " 'doubtful',\n",
       " 'showing',\n",
       " 'bathroom',\n",
       " 'suite',\n",
       " 'dipper',\n",
       " 'host',\n",
       " '180',\n",
       " 'desperately',\n",
       " 'leagues',\n",
       " 'protected',\n",
       " 'near',\n",
       " 'contributions',\n",
       " 'gaze',\n",
       " 'ultrasonic',\n",
       " 'Iliad',\n",
       " 'unwed',\n",
       " 'advised',\n",
       " 'sold',\n",
       " 'permanent',\n",
       " 'King',\n",
       " 'switch',\n",
       " 'integrity',\n",
       " 'temple',\n",
       " 'marched',\n",
       " 'nilpotent',\n",
       " 'creativity',\n",
       " 'Monsieur',\n",
       " 'democratic',\n",
       " 'mountains',\n",
       " 'counsel',\n",
       " 'relevance',\n",
       " 'negligible',\n",
       " 'defined',\n",
       " 'division',\n",
       " 'civil',\n",
       " 'politician',\n",
       " 'ridiculous',\n",
       " 'higher',\n",
       " \"Krim's\",\n",
       " 'routine',\n",
       " 'Chapel',\n",
       " 'divided',\n",
       " 'herds',\n",
       " 'statutory',\n",
       " 'endure',\n",
       " 'missing',\n",
       " 'exciting',\n",
       " 'drug',\n",
       " 'Fifth',\n",
       " 'exercised',\n",
       " 'shouted',\n",
       " 'please',\n",
       " 'cluster',\n",
       " 'Lucille',\n",
       " 'Community',\n",
       " 'nailed',\n",
       " 'compounds',\n",
       " 'Naturally',\n",
       " 'x-ray',\n",
       " 'boil',\n",
       " 'surprise',\n",
       " 'numbered',\n",
       " 'symphonic',\n",
       " 'sung',\n",
       " 'secrecy',\n",
       " 'greeted',\n",
       " 'Navy',\n",
       " 'dangerous',\n",
       " 'magnificent',\n",
       " 'supervision',\n",
       " 'Income',\n",
       " 'estimates',\n",
       " 'screwed',\n",
       " 'Morton',\n",
       " 'believes',\n",
       " 'approach',\n",
       " 'Liberal',\n",
       " 'expressing',\n",
       " 'Despite',\n",
       " 'estate',\n",
       " 'catch',\n",
       " 'Frequently',\n",
       " 'reserve',\n",
       " 'diplomatic',\n",
       " 'ribbon',\n",
       " 'grin',\n",
       " 'making',\n",
       " 'privilege',\n",
       " 'alternately',\n",
       " 'justified',\n",
       " 'accurately',\n",
       " 'number',\n",
       " 'Henrietta',\n",
       " 'taxed',\n",
       " 'meanings',\n",
       " 'downward',\n",
       " 'hang',\n",
       " 'confronting',\n",
       " 'farmer',\n",
       " 'Remember',\n",
       " 'Mahayana',\n",
       " 'eliminated',\n",
       " 'civilian',\n",
       " 'dinner',\n",
       " 'urges',\n",
       " 'lands',\n",
       " '2:36',\n",
       " 'unsuccessful',\n",
       " 'Pirates',\n",
       " 'getting',\n",
       " 'Eichmann',\n",
       " 'Local',\n",
       " 'norm',\n",
       " 'remained',\n",
       " 'thickness',\n",
       " 'bounced',\n",
       " 'due',\n",
       " 'Castro',\n",
       " 'Bermuda',\n",
       " 'panic',\n",
       " 'today',\n",
       " 'cockpit',\n",
       " 'mm.',\n",
       " 'voting',\n",
       " 'seventeen',\n",
       " 'Franklin',\n",
       " 'Hughes',\n",
       " 'Emory',\n",
       " 'nice',\n",
       " 'martyr',\n",
       " 'foam',\n",
       " 'decent',\n",
       " 'Supreme',\n",
       " 'guts',\n",
       " 'cities',\n",
       " 'operational',\n",
       " 'Pope',\n",
       " 'tanned',\n",
       " 'significance',\n",
       " 'knocked',\n",
       " 'minority',\n",
       " 'pot',\n",
       " 'slick',\n",
       " 'sitting',\n",
       " 'communication',\n",
       " 'depression',\n",
       " 'later',\n",
       " 'herd',\n",
       " 'involution',\n",
       " 'owe',\n",
       " 'equals',\n",
       " 'persuaded',\n",
       " 'hatred',\n",
       " 'tumor',\n",
       " 'trained',\n",
       " 'Figures',\n",
       " 'shelters',\n",
       " 'blue',\n",
       " 'sleeve',\n",
       " 'kept',\n",
       " 'forward',\n",
       " 'pays',\n",
       " 'Jessica',\n",
       " 'Meltzer',\n",
       " '15',\n",
       " 'examined',\n",
       " 'reviews',\n",
       " 'thirteen',\n",
       " 'L.',\n",
       " 'twist',\n",
       " 'thrust',\n",
       " 'deputy',\n",
       " 'Wisman',\n",
       " 'characterization',\n",
       " 'ordinary',\n",
       " 'Rep.',\n",
       " 'Norton',\n",
       " 'curtains',\n",
       " 'preparation',\n",
       " 'heroes',\n",
       " 'Flannagan',\n",
       " 'local',\n",
       " 'periodic',\n",
       " 'psychologist',\n",
       " 'trail',\n",
       " 'socialism',\n",
       " 'attributable',\n",
       " 'international',\n",
       " 'twins',\n",
       " 'neat',\n",
       " 'Seven',\n",
       " 'deep',\n",
       " 'bat',\n",
       " 'bolted',\n",
       " 'identified',\n",
       " 'causes',\n",
       " 'bottoms',\n",
       " 'twin',\n",
       " 'conservatism',\n",
       " 'Aug.',\n",
       " 'downstairs',\n",
       " 'convenient',\n",
       " 'thyroxine',\n",
       " 'folklore',\n",
       " 'remote',\n",
       " 'bench',\n",
       " 'prepare',\n",
       " 'sixty',\n",
       " 'bones',\n",
       " 'hopeful',\n",
       " 'requested',\n",
       " 'capita',\n",
       " 'exclude',\n",
       " 'Swadesh',\n",
       " 'Boys',\n",
       " 'acted',\n",
       " 'estimated',\n",
       " 'chiefly',\n",
       " 'cyclist',\n",
       " 'claim',\n",
       " 'ugliness',\n",
       " 'Spring',\n",
       " 'gravely',\n",
       " 'refusing',\n",
       " 'aborigine',\n",
       " 'found',\n",
       " 'tax-exempt',\n",
       " 'plates',\n",
       " 'abruptly',\n",
       " 'condition',\n",
       " 'unusual',\n",
       " 'firing',\n",
       " 'evidenced',\n",
       " 'commuter',\n",
       " 'culture',\n",
       " 'boast',\n",
       " 'supplies',\n",
       " 'engages',\n",
       " 'whiskey',\n",
       " '$10,000',\n",
       " 'Selden',\n",
       " 'might',\n",
       " 'business',\n",
       " 'findings',\n",
       " 'goal',\n",
       " 'guides',\n",
       " 'nonspecific',\n",
       " 'Moore',\n",
       " 'procurement',\n",
       " 'wholesome',\n",
       " 'new',\n",
       " 'breast',\n",
       " 'secular',\n",
       " 'debt',\n",
       " 'malaise',\n",
       " \"they're\",\n",
       " 'art',\n",
       " 'peculiarly',\n",
       " 'fans',\n",
       " 'security',\n",
       " 'reactor',\n",
       " 'Special',\n",
       " 'Interior',\n",
       " 'inspired',\n",
       " 'Jenkins',\n",
       " 'dots',\n",
       " 'armies',\n",
       " 'promptly',\n",
       " 'servants',\n",
       " 'mating',\n",
       " 'avoid',\n",
       " 'aesthetic',\n",
       " 'pasture',\n",
       " 'Palfrey',\n",
       " 'London',\n",
       " 'Artists',\n",
       " 'pair',\n",
       " 'Something',\n",
       " '50',\n",
       " 'Word',\n",
       " 'advertised',\n",
       " 'rivers',\n",
       " 'production',\n",
       " 'commonplace',\n",
       " 'steeple',\n",
       " 'tells',\n",
       " 'Aj',\n",
       " 'Cubism',\n",
       " 'warned',\n",
       " 'go',\n",
       " 'General',\n",
       " 'pleasing',\n",
       " 'foams',\n",
       " 'Rhode',\n",
       " 'outward',\n",
       " 'broadcast',\n",
       " 'Pathet',\n",
       " 'makers',\n",
       " 'boat',\n",
       " 'tracks',\n",
       " 'trades',\n",
       " 'demanding',\n",
       " 'Virgin',\n",
       " 'McBride',\n",
       " 'attached',\n",
       " 'Good',\n",
       " 'prevents',\n",
       " 'lousy',\n",
       " 'rusty',\n",
       " 'certain',\n",
       " 'sliding',\n",
       " '5',\n",
       " 'expenditures',\n",
       " 'shooting',\n",
       " 'principles',\n",
       " 'fabrics',\n",
       " 'intense',\n",
       " 'exposure',\n",
       " 'white',\n",
       " '**zg',\n",
       " 'twelve',\n",
       " 'vigorously',\n",
       " 'installations',\n",
       " 'blinked',\n",
       " 'plan',\n",
       " 'screws',\n",
       " 'emergency',\n",
       " 'awful',\n",
       " 'celebration',\n",
       " 'stolen',\n",
       " 'bars',\n",
       " 'musicians',\n",
       " 'thinking',\n",
       " 'isolated',\n",
       " 'Beowulf',\n",
       " 'reaction',\n",
       " 'convert',\n",
       " 'primitive',\n",
       " 'disastrous',\n",
       " 'Langford',\n",
       " 'weapon',\n",
       " 'contrasts',\n",
       " 'frightful',\n",
       " 'increased',\n",
       " 'churches',\n",
       " 'enclosure',\n",
       " 'Daniel',\n",
       " 'micrometeorite',\n",
       " 'feelings',\n",
       " 'model',\n",
       " 'proud',\n",
       " 'Simms',\n",
       " 'Eisenhower',\n",
       " 'note',\n",
       " 'combined',\n",
       " 'regional',\n",
       " 'derived',\n",
       " 'vitality',\n",
       " 'proves',\n",
       " 'Truman',\n",
       " 'Swift',\n",
       " 'Manhattan',\n",
       " 'sufficient',\n",
       " 'organisms',\n",
       " 'Mayor',\n",
       " 'declared',\n",
       " 'Michael',\n",
       " 'furnace',\n",
       " 'Succession',\n",
       " 'suggestive',\n",
       " 'recalls',\n",
       " 'Cattle',\n",
       " 'Fighting',\n",
       " 'steep',\n",
       " 'emission',\n",
       " 'upset',\n",
       " 'screen',\n",
       " 'Guy',\n",
       " 'footsteps',\n",
       " 'hand',\n",
       " 'Administration',\n",
       " 'attendants',\n",
       " 'make',\n",
       " 'enemy',\n",
       " 'jerked',\n",
       " 'restraining',\n",
       " 'dreams',\n",
       " 'anchored',\n",
       " 'grill',\n",
       " 'ft.',\n",
       " 'grip',\n",
       " 'colleges',\n",
       " 'sometimes',\n",
       " 'gate',\n",
       " 'observing',\n",
       " 'board',\n",
       " 'seated',\n",
       " '100,000',\n",
       " 'preceding',\n",
       " 'unemployment',\n",
       " 'tropical',\n",
       " '2:35',\n",
       " 'graduate',\n",
       " '27',\n",
       " 'tell',\n",
       " 'box',\n",
       " 'welcome',\n",
       " 'woman',\n",
       " 'implied',\n",
       " 'semester',\n",
       " 'fight',\n",
       " 'excitement',\n",
       " 'Model',\n",
       " 'reign',\n",
       " 'quote',\n",
       " 'enterprise',\n",
       " 'geometry',\n",
       " 'maker',\n",
       " 'inch',\n",
       " 'Jay',\n",
       " 'cleaner',\n",
       " 'momentous',\n",
       " 'rhythms',\n",
       " 'ranchers',\n",
       " 'loudly',\n",
       " 'window',\n",
       " 'TV',\n",
       " 'corresponding',\n",
       " 'Benington',\n",
       " 'selling',\n",
       " 'consultants',\n",
       " 'Future',\n",
       " 'Finally',\n",
       " 'band',\n",
       " 'integrate',\n",
       " 'unrelated',\n",
       " 'material',\n",
       " 'prisoners',\n",
       " 'consciously',\n",
       " 'Hence',\n",
       " 'tank',\n",
       " '40,000',\n",
       " 'liberalism',\n",
       " 'WTV',\n",
       " 'cases',\n",
       " 'formally',\n",
       " 'sick',\n",
       " 'dies',\n",
       " 'prime',\n",
       " '1957',\n",
       " 'temporarily',\n",
       " 'attendance',\n",
       " 'Nogol',\n",
       " 'splendor',\n",
       " 'mice',\n",
       " 'Beatrice',\n",
       " 'thinks',\n",
       " 'heap',\n",
       " 'congressmen',\n",
       " 'leadership',\n",
       " 'character',\n",
       " 'floors',\n",
       " 'Caribbean',\n",
       " 'denial',\n",
       " 'five',\n",
       " 'sympathies',\n",
       " 'youngster',\n",
       " 'shorter',\n",
       " 'orbits',\n",
       " 'engage',\n",
       " 'conscience',\n",
       " 'fourteen',\n",
       " 'separation',\n",
       " 'flight',\n",
       " \"people's\",\n",
       " 'Arlen',\n",
       " 'react',\n",
       " 'hull',\n",
       " 'executive',\n",
       " 'builder',\n",
       " 'obvious',\n",
       " 'interval',\n",
       " 'earn',\n",
       " 'stone',\n",
       " 'supply',\n",
       " 'Ever',\n",
       " 'wicked',\n",
       " 'coupled',\n",
       " 'investigate',\n",
       " 'varied',\n",
       " 'ancestry',\n",
       " 'paused',\n",
       " 'Dean',\n",
       " 'doubt',\n",
       " 'honor',\n",
       " 'Marine',\n",
       " 'Alaska',\n",
       " 'depressed',\n",
       " 'explicit',\n",
       " 'motel',\n",
       " 'variable',\n",
       " 'spends',\n",
       " 'noon',\n",
       " 'fantastic',\n",
       " 'garment',\n",
       " 'answer',\n",
       " 'signal',\n",
       " 'waving',\n",
       " 'Ohio',\n",
       " 'preoccupation',\n",
       " 'persuasion',\n",
       " 'conflicting',\n",
       " 'activity',\n",
       " 'challenging',\n",
       " 'superstition',\n",
       " 'poor',\n",
       " 'income',\n",
       " 'totals',\n",
       " 'splendid',\n",
       " 'paid',\n",
       " 'complicated',\n",
       " 'cafe',\n",
       " 'attending',\n",
       " 'Illinois',\n",
       " 'forthcoming',\n",
       " 'Woodruff',\n",
       " 'orbit',\n",
       " 'learns',\n",
       " 'objection',\n",
       " 'tide',\n",
       " 'liquids',\n",
       " 'oxygen',\n",
       " 'mingled',\n",
       " 'fine',\n",
       " 'territorial',\n",
       " 'garden',\n",
       " 'Protestantism',\n",
       " 'SAC',\n",
       " 'happy',\n",
       " 'reject',\n",
       " 'specified',\n",
       " 'chairmen',\n",
       " 'Piano',\n",
       " 'Cambridge',\n",
       " 'diplomacy',\n",
       " 'greet',\n",
       " 'enforcement',\n",
       " 'suppose',\n",
       " 'soldier',\n",
       " 'Portland',\n",
       " 'Holden',\n",
       " '1947',\n",
       " 'ring',\n",
       " 'shipping',\n",
       " 'stockholders',\n",
       " 'teaching',\n",
       " 'loud',\n",
       " '100',\n",
       " 'Dr.',\n",
       " 'ions',\n",
       " 'blend',\n",
       " 'speakers',\n",
       " 'trivial',\n",
       " 'Gavin',\n",
       " 'bureau',\n",
       " 'raise',\n",
       " 'good',\n",
       " 'Italians',\n",
       " 'Carl',\n",
       " 'unquestionably',\n",
       " 'remarkably',\n",
       " 'retirement',\n",
       " 'carbine',\n",
       " 'opinions',\n",
       " 'containing',\n",
       " 'essential',\n",
       " 'akin',\n",
       " 'insight',\n",
       " 'spear',\n",
       " 'Welch',\n",
       " 'fighter',\n",
       " 'liver',\n",
       " 'approaches',\n",
       " 'least',\n",
       " 'captain',\n",
       " 'pastors',\n",
       " 'repairs',\n",
       " 'said',\n",
       " 'palms',\n",
       " 'Rather',\n",
       " \"Patchen's\",\n",
       " 'behavior',\n",
       " 'protection',\n",
       " 'quack',\n",
       " 'country',\n",
       " 'entertain',\n",
       " 'Madden',\n",
       " 'engineers',\n",
       " 'potent',\n",
       " 'ignorant',\n",
       " 'sophisticated',\n",
       " 'homogeneous',\n",
       " 'Unfortunately',\n",
       " 'prospects',\n",
       " \"Steele's\",\n",
       " 'occurred',\n",
       " 'fashion',\n",
       " 'put',\n",
       " 'juvenile',\n",
       " 'island',\n",
       " 'taking',\n",
       " 'Harlem',\n",
       " 'spin',\n",
       " 'glands',\n",
       " 'bond',\n",
       " 'served',\n",
       " 'bodies',\n",
       " 'west',\n",
       " 'intentions',\n",
       " 'part',\n",
       " 'Pont',\n",
       " 'interlobular',\n",
       " 'notice',\n",
       " 'Academy',\n",
       " 'oldest',\n",
       " 'harness',\n",
       " 'gun',\n",
       " 'organic',\n",
       " 'two-story',\n",
       " 'abandoned',\n",
       " 'answering',\n",
       " 'financially',\n",
       " 'lung',\n",
       " 'Garden',\n",
       " 'superior',\n",
       " 'assigning',\n",
       " 'along',\n",
       " 'Lodge',\n",
       " 'intensity',\n",
       " 'scholarship',\n",
       " 'studying',\n",
       " 'Morse',\n",
       " 'feature',\n",
       " 'Mr.',\n",
       " 'begun',\n",
       " 'Black',\n",
       " 'seems',\n",
       " 'thou',\n",
       " 'mount',\n",
       " 'illusion',\n",
       " 'scholar',\n",
       " 'veiled',\n",
       " 'equally',\n",
       " 'sacrifice',\n",
       " 'nodded',\n",
       " 'began',\n",
       " 'Kansas',\n",
       " 'Premier',\n",
       " 'peering',\n",
       " 'Must',\n",
       " 'swing',\n",
       " 'dash',\n",
       " 'legends',\n",
       " 'surprised',\n",
       " 'unhappy',\n",
       " 'crucial',\n",
       " 'Joe',\n",
       " 'dwell',\n",
       " 'Harold',\n",
       " 'panel',\n",
       " 'cigarette',\n",
       " 'join',\n",
       " 'tasks',\n",
       " 'eighteen',\n",
       " 'Oklahoma',\n",
       " 'calcium',\n",
       " 'scared',\n",
       " 'eighth',\n",
       " 'devote',\n",
       " 'rubber',\n",
       " 'slaves',\n",
       " 'insisted',\n",
       " 'reads',\n",
       " 'conscious',\n",
       " 'tie',\n",
       " 'deduced',\n",
       " 'killed',\n",
       " 'second',\n",
       " 'convenience',\n",
       " 'devil',\n",
       " 'man',\n",
       " 'beckoned',\n",
       " 'swear',\n",
       " 'vector',\n",
       " 'varies',\n",
       " 'soil',\n",
       " 'rooms',\n",
       " 'stream',\n",
       " 'rails',\n",
       " 'Emperor',\n",
       " 'anti-slavery',\n",
       " 'protozoa',\n",
       " 'specialists',\n",
       " 'canvases',\n",
       " 'calibration',\n",
       " 'dictates',\n",
       " 'indeed',\n",
       " 'tourist',\n",
       " 'True',\n",
       " 'shores',\n",
       " 'performance',\n",
       " 'mechanical',\n",
       " 'questionnaires',\n",
       " 'velocity',\n",
       " 'theme',\n",
       " 'knife',\n",
       " 'leave',\n",
       " 'decisive',\n",
       " 'avoiding',\n",
       " 'Barnett',\n",
       " 'broader',\n",
       " 'meat',\n",
       " 'Sam',\n",
       " 'votes',\n",
       " 'dream',\n",
       " 'purposes',\n",
       " 'Mercer',\n",
       " 'ration',\n",
       " 'contributed',\n",
       " 'Morris',\n",
       " 'Democratic',\n",
       " 'gains',\n",
       " 'Journal',\n",
       " 'realities',\n",
       " 'involve',\n",
       " 'truly',\n",
       " 'Listen',\n",
       " 'Protestants',\n",
       " 'crawl',\n",
       " 'viewed',\n",
       " 'cents',\n",
       " 'advocate',\n",
       " 'Brandt',\n",
       " 'differential',\n",
       " 'parlor',\n",
       " 'Pulley',\n",
       " 'military',\n",
       " 'Asian',\n",
       " 'gentleman',\n",
       " 'Rod',\n",
       " 'hardship',\n",
       " \"Peter's\",\n",
       " 'recession',\n",
       " 'seeming',\n",
       " 'dazzling',\n",
       " 'surroundings',\n",
       " 'forms',\n",
       " 'separately',\n",
       " 'junior',\n",
       " 'Square',\n",
       " 'movie',\n",
       " 'planning',\n",
       " 'exhaust',\n",
       " 'theatrical',\n",
       " 'galaxies',\n",
       " 'directions',\n",
       " 'cried',\n",
       " 'willing',\n",
       " 'Bill',\n",
       " 'capabilities',\n",
       " 'assumed',\n",
       " 'view',\n",
       " 'lesser',\n",
       " 'pulling',\n",
       " 'treasurer',\n",
       " 'understanding',\n",
       " 'completely',\n",
       " 'repeat',\n",
       " 'phrase',\n",
       " 'simply',\n",
       " 'discriminating',\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3158])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish = torch.LongTensor([word2index['dog']])\n",
    "fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4071,  0.0078]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish_embed_c = model.embedding_center(fish)\n",
    "fish_embed_o = model.embedding_outside(fish)\n",
    "fish_embed   = (fish_embed_c + fish_embed_o) / 2\n",
    "fish_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5963, -0.0380]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish_embed_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(word):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except:\n",
    "        index = word2index['<UNK>']\n",
    "        \n",
    "    word = torch.LongTensor([word2index[word]])\n",
    "    \n",
    "    embed_c = model.embedding_center(word)\n",
    "    embed_o = model.embedding_outside(word)\n",
    "    embed   = (embed_c + embed_o) / 2\n",
    "    \n",
    "    return embed[0][0].item(), embed[0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5301620364189148, -1.1365153789520264)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('animal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2453116923570633, 0.5773712992668152)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.40714454650878906, 0.00776178203523159)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.7001842260360718, 1.021337866783142)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embed('fish')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.7001842260360718, 1.021337866783142)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish = get_embed('fish')\n",
    "fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.021597012877464294, 0.7026581168174744)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruit = get_embed('fruit')\n",
    "fruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7222745418548584, 0.12681323289871216)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk = get_embed('<UNK>')\n",
    "unk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3762060843055579"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(fish) @ np.array(unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4142900904790245\n",
      "0.807029211856514\n"
     ]
    }
   ],
   "source": [
    "#more formally is to divide by its norm\n",
    "def cosine_similarity(A, B):\n",
    "    dot_product = np.dot(A, B)\n",
    "    norm_a = np.linalg.norm(A)\n",
    "    norm_b = np.linalg.norm(B)\n",
    "    similarity = dot_product / (norm_a * norm_b)\n",
    "    return similarity\n",
    "\n",
    "print(cosine_similarity(np.array(fish), np.array(unk)))\n",
    "print(cosine_similarity(np.array(fish), np.array(fruit)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pickle of the model\n",
    "import pickle\n",
    "\n",
    "with open('skipgram.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
